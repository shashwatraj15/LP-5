{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "# There are 10 image classes in this dataset and each class has a mapping corresponding to the following labels:\n",
    "#0 T-shirt/top\n",
    "#1 Trouser\n",
    "#2 pullover\n",
    "#3 Dress\n",
    "#4 Coat\n",
    "#5 sandals\n",
    "#6 shirt\n",
    "#7 sneaker\n",
    "#8 bag\n",
    "#9 ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27fb2effaf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27fb2fb1b80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will preprocess the data by scaling the pixel values to be between 8 and 1, and then reshaping the images to be 28x28 pixels.\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# 28, 28 comes from width, height, 1 comes from the number of channels\n",
    "# -1 means that the length in that dimension is inferred.\n",
    "# This is done based on the constraint that the number of elements in an ndarray or Tensor when reshaped must remain the same.\n",
    "\n",
    "# each image is a row vector (784 elements) and there are lots of such rows (let it be n, so there are 784n elements). So TensorFlow can\n",
    "\n",
    "# converting the training_images array to 4 dimensional array with sizes 60068, 28, 28, 1 for @th to 3rd dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 13, 13, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               147584    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 241,546\n",
      "Trainable params: 241,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We will use a convolutional neural network (CNN) to classify the fashion items.\n",
    "# The CNN will consist of multiple convolutional layers followed by max pooling,\n",
    "# dropout, and dense layers. Here is the code for the model:\n",
    "\n",
    "model = keras.Sequential([\n",
    "  keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "  # 32 filters (default), randomly initialized\n",
    "  # 3*3 is Size of Filter\n",
    "  # 28,28,1 size of Input Image\n",
    "  # No zero-padding: every output 2 pixels less in every dimension\n",
    "  # in Paramter shwon 320 is value of weights: (3x3 filter weights + 32 bias) * 32 filters\n",
    "  # 32*3*3-288(Total)+32(bias)= 320\n",
    "\n",
    "  keras.layers.MaxPooling2D((2,2)),\n",
    "  # It shown 13 * 13 size image with 32 channel or filter or depth.\n",
    "\n",
    "  keras.layers.Dropout(0.25),\n",
    "  # Reduce Overfitting of Training sample drop out 25% Neuron\n",
    "\n",
    "  keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  # Deeper layers use 64 filters\n",
    "  # 3*3 is Size of Filter\n",
    "  # Observe how the input image on 28x28x1 is transformed to a 3x3x64 feature map\n",
    "  # 13(Size)-3(Filter Size )+1(bias)=11 Size for Width and Height with 64 Depth or filtter or channel\n",
    "  # in Paramter shwon 18496 is value of weights: (3x3 filter weights + 64 bias) * 64 filters\n",
    "  # 64*3*3=576+1=577%32 + 32(bias)=18496\n",
    "\n",
    "  keras.layers.MaxPooling2D((2,2)),\n",
    "  # It shown 5 * 5 size image with 64 channel or filter or depth.\n",
    "\n",
    "  keras.layers.Dropout(0.25),\n",
    "\n",
    "  keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "  # Deeper layers use 128 filters\n",
    "  # 3*3 is Size of Filter\n",
    "  # Observe how the lnput image on 28x28x1 is transformed to a 3x3x128 feature map\n",
    "  # It show 5(Size)-3(Filter Size )+1(bias)=3 Size for Width and Height with 64 Depth or filtter or channel\n",
    "  # 128*3*3=1152+1=1153*64 + 64(blas)= 73856\n",
    "\n",
    "  # To classify the images, we still need a Dense and Softmax layer.\n",
    "  # We need to flatten the 3x3x128 feature map to a vector of size 1152\n",
    "  # https://medium.com/@iamvarman/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca\n",
    "\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(128, activation='relu'),\n",
    "  # 128 Size of Node in Dense Layer\n",
    "  # 1152*128 = 147584\n",
    "\n",
    "  keras.layers.Dropout(0.25),\n",
    "  keras.layers.Dense(10, activation='softmax')\n",
    "  # 10 Size of Node another Dense Layer\n",
    "  # 128*10+1@ bias= 1290\n",
    "])\n",
    "\n",
    "model.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 0.5732 - accuracy: 0.7880 - val_loss: 0.3825 - val_accuracy: 0.8602\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.3751 - accuracy: 0.8625 - val_loss: 0.3360 - val_accuracy: 0.8791\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.3282 - accuracy: 0.8805 - val_loss: 0.3017 - val_accuracy: 0.8902\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.3006 - accuracy: 0.8896 - val_loss: 0.2865 - val_accuracy: 0.8926\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.2785 - accuracy: 0.8977 - val_loss: 0.2724 - val_accuracy: 0.9003\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.2652 - accuracy: 0.9016 - val_loss: 0.2586 - val_accuracy: 0.9042\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.2558 - accuracy: 0.9043 - val_loss: 0.2460 - val_accuracy: 0.9095\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.2444 - accuracy: 0.9092 - val_loss: 0.2502 - val_accuracy: 0.9076\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.2361 - accuracy: 0.9099 - val_loss: 0.2489 - val_accuracy: 0.9096\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.2289 - accuracy: 0.9142 - val_loss: 0.2407 - val_accuracy: 0.9113\n"
     ]
    }
   ],
   "source": [
    "# Compile and Train the Model\n",
    "# After defining the model, we will compile it and train it on the training data.\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test))\n",
    "# 1875 is a number of batches. By default batches contain 32 samles.60000\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2407 - accuracy: 0.9113\n",
      "Test accuracy: 0.911300003528595\n"
     ]
    }
   ],
   "source": [
    "# Finally, we will evaluate the performance of the model on the test data.\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
